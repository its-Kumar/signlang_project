{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow lite model\n",
    "\n",
    "Converting the Keras model to lite model for egde devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import os\n",
    "from sys import getsizeof\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get model size\n",
    "def get_folder_size(folder_path: str):\n",
    "    size = 0\n",
    "    for path, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            fp = os.path.join(path, file)\n",
    "            size += os.path.getsize(fp)\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME = \"../models/3_sl_aug_model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(KERAS_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                12312     \n",
      "=================================================================\n",
      "Total params: 560,856\n",
      "Trainable params: 560,632\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Model Size: 4877596 Bytes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Keras Model Size: {get_folder_size(KERAS_MODEL_NAME)} Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test set to calculate model accuracy\n",
    "import pandas as pd\n",
    "\n",
    "valid_df = pd.read_csv(\"../data/asl_data/sign_mnist_valid.csv\")\n",
    "\n",
    "# Separate out our target values\n",
    "y_test = valid_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "# Separate out our image vectors\n",
    "x_test = valid_df.values\n",
    "\n",
    "y_test_numpy = y_test.values\n",
    "y_test = keras.utils.to_categorical(y_test, 24)\n",
    "\n",
    "# Normalize our image data\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9989\n",
      "loss: 0.002462963340803981, Accuracy: 0.9988845586776733\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"loss: {loss}, Accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_NAME = \"../models/5_sl_lite.tflite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\KUMAR~1.SHA\\AppData\\Local\\Temp\\tmp5ciphr5s\\assets\n"
     ]
    }
   ],
   "source": [
    "# Model convertor\n",
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_model = tf_lite_converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "with open(TF_LITE_MODEL_NAME, \"wb\") as f:\n",
    "    f.write(tf_lite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2248212 Bytes\n"
     ]
    }
   ],
   "source": [
    "# size of the saved model\n",
    "print(f\"Model size: {os.path.getsize(TF_LITE_MODEL_NAME)} Bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4609262431738914"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size comparison with keras model\n",
    "os.path.getsize(TF_LITE_MODEL_NAME) / get_folder_size(KERAS_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter for tflite model\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_NAME)\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'conv2d_input',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 28, 28,  1]),\n",
       "  'shape_signature': array([-1, 28, 28,  1]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Identity',\n",
       "  'index': 33,\n",
       "  'shape': array([ 1, 24]),\n",
       "  'shape_signature': array([-1, 24]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [ 1 28 28  1]\n",
      "Input type: <class 'numpy.float32'>\n",
      "output Shape: [ 1 24]\n",
      "output type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input Shape: {input_details[0]['shape']}\")\n",
    "print(f\"Input type: {input_details[0]['dtype']}\")\n",
    "print(f\"output Shape: {output_details[0]['shape']}\")\n",
    "print(f\"output type: {output_details[0]['dtype']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_numpy = np.array(x_test, dtype=np.float32)\n",
    "x_test_numpy.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 28, 28, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_numpy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 24)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize tensor shape\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], x_test_numpy.shape)\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], y_test.shape)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [7172   28   28    1]\n",
      "Input type: <class 'numpy.float32'>\n",
      "output Shape: [7172   24]\n",
      "output type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input Shape: {input_details[0]['shape']}\")\n",
    "print(f\"Input type: {input_details[0]['dtype']}\")\n",
    "print(f\"output Shape: {output_details[0]['shape']}\")\n",
    "print(f\"output type: {output_details[0]['dtype']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], x_test_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_prediction = interpreter.get_tensor(output_details[0]['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results shape: (7172, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction results shape: {tflite_prediction.shape}\")\n",
    "prediction_classes = np.argmax(tflite_prediction, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 9, ..., 2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 9, ..., 2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of TFLite Model: 0.9988845510317903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(prediction_classes, y_test_numpy)\n",
    "print(f\"Accuracy of TFLite Model: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLite Model Float16\n",
    "\n",
    "converting to more reduced size model by using float 16 instead of float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_FLOAT16_MODEL_NAME = \"../models/tf_lite_float16.tflite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\KUMAR~1.SHA\\AppData\\Local\\Temp\\tmpx7yvglsw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\KUMAR~1.SHA\\AppData\\Local\\Temp\\tmpx7yvglsw\\assets\n"
     ]
    }
   ],
   "source": [
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
    "tf_lite_model = tf_lite_converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TF_LITE_FLOAT16_MODEL_NAME, \"wb\") as f:\n",
    "    f.write(tf_lite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 1129472 Bytes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size: {os.path.getsize(TF_LITE_FLOAT16_MODEL_NAME)} Bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23156325370120853"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size comparison\n",
    "os.path.getsize(TF_LITE_FLOAT16_MODEL_NAME) / get_folder_size(KERAS_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.502386785587836"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(TF_LITE_FLOAT16_MODEL_NAME) / \\\n",
    "    os.path.getsize(TF_LITE_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of TFLite Model: 0.9988845510317903\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_NAME)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "# resize tensor shape\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], x_test_numpy.shape)\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], y_test.shape)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], x_test_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_prediction = interpreter.get_tensor(output_details[0]['index'])\n",
    "prediction_classes = np.argmax(tflite_prediction, axis=1)\n",
    "\n",
    "acc = accuracy_score(prediction_classes, y_test_numpy)\n",
    "print(f\"Accuracy of TFLite Model: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
